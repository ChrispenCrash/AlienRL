Need to investigate python packages for inputting data into game
Options:
* import pynput # pip install pynput
* import vgamepad # pip install vgamepad
* import pyvjoy # pip install pyvjoy
* import pyvjoystick # pip install pyvjoystick

Links:
https://rishavghosh605.medium.com/how-to-create-your-first-vjoy-application-8a01dad75c0a

Nordschleife leaderboard
http://www.radiators-champ.com/RSRLiveTiming/index.php?page=rank&track=1006&car=4760&rank_type=all&tyre_type=all&controller_type=all&community=all&friends=all

Shared Memory
https://realpython.com/python-mmap/

NB: Lap invalidated if 3 or more wheels off track

Important research papers
https://spinningup.openai.com/en/latest/spinningup/keypapers.html

Use lost of connection to assetto corsa to detect when game is paused.

Count model parameters
pytorch_total_params = sum(p.numel() for p in model.parameters())

Count only trainable model parameters
pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

Combining image and tabular data
https://towardsdatascience.com/integrating-image-and-tabular-data-for-deep-learning-9281397c7318
https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/
Paper: Transferring Deep Visual Semantic Features to Large-Scale Multimodal Learning to Rank

PPO Latex
https://nn.labml.ai/rl/ppo/index.html

Reinforcement Learning Tips and Tricks
https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html

Some research papers on RL
https://modelzoo.co/model/deep-reinforcement-learning-with-pytorch

Which RL algorithm to choose?
https://medium.datadriveninvestor.com/which-reinforcement-learning-rl-algorithm-to-use-where-when-and-in-what-scenario-e3e7617fb0b1

Framestacking
https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/

Q-Learning Tutorial by Sentdex
https://pythonprogramming.net/q-learning-reinforcement-learning-python-tutorial/

Resizing and downsampling
https://becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26

Plotting style
plt.style.use['science']
with plt.style.context(combo):
    plt.figure(figsize=(10, 5))
    plt.title('Tanh Function', fontsize=20, fontweight='bold')

Proximal Policy Optimization (PPO) Explained
https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b
https://skrl.readthedocs.io/en/latest/modules/skrl.agents.ppo.html

PPO PyTorch Example
https://pytorch.org/tutorials/intermediate/reinforcement_ppo.html

Stable-baselines3 on Continuous Env Highway-Env
https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#hindsight-experience-replay-her

Investigate
https://notanymike.github.io/Solving-CarRacing/
https://github.com/alirezakazemipour/Continuous-PPO/tree/master
https://github.com/araffin/awesome-real-world-rl
https://github.com/elsheikh21/car-racing-ppo
https://github.com/AGiannoutsos/car_racer_gym	See RL_PPO2.ipynb in Colab
https://github.com/araffin/rl-handson-rlvs21/blob/main/rlvs_hands_on_sb3.ipynb  Custom environments for Stable-baselines3

Examples of PPO in a continuous environment
https://github.com/Farama-Foundation/HighwayEnv/blob/master/scripts/sb3_racetracks_ppo.py
https://github.com/elsheikh21/car-racing-ppo
https://github.com/leonjovanovic/drl-ppo-bipedal-walker
https://github.com/pythonlessons/Reinforcement_Learning/tree/master/BipedalWalker-v3_PPO - with accompanying youtube video (https://www.youtube.com/watch?v=lYP3cF2wqOY) & (https://www.youtube.com/playlist?list=PLbMO9c_jUD47r9QZKpLn5CY_Mt-NFY8cC) & (https://pylessons.com/PPO-reinforcement-learning)
https://github.com/quantumiracle/Popular-RL-Algorithms contains 3 PPO scripts

Examples of SAC in a continuous environment
https://github.com/lollcat/Soft-Actor-Critic
https://github.com/timoklein/car_racer
https://github.com/toshikwa/soft-actor-critic.pytorch
https://github.com/toshikwa/gail-airl-ppo.pytorch
https://github.com/BY571/Soft-Actor-Critic-and-Extensions
https://github.com/pranz24/pytorch-soft-actor-critic
"StableBaselines3 - HighWayEnv - Continuous.ipynb" in Colab

Custom Gymnasium Environments
https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html#advanced-example - Custom policies

Examples of TD3 in a continuous environment
https://towardsdatascience.com/td3-learning-to-run-with-ai-40dfc512f93 & (https://github.com/djbyrne/TD3) & (TD3.ipynb in Colab folder)
https://github.com/sfujim/TD3/tree/master

Possible way of finding distance to walls as well converting a video game to a gym environment
https://www.reddit.com/r/MachineLearning/comments/ia93ao/p_i_made_an_ai_that_can_drive_in_a_real_racing/ (https://www.youtube.com/watch?v=Ul20KgkW2ZM) & (https://www.youtube.com/watch?v=_oNK08LvZ-g)
https://github.com/AndrejGobeX/TrackMania_AI especially https://github.com/AndrejGobeX/TrackMania_AI/blob/main/TMEnv.py, converts trackmania to gym env.

Similiar car racing environments
https://github.com/learn-to-race/l2r

Code refactor needed
* Instead of waiting every (1/GAME_FPS)*frameskip to read a frame, should instead read in every frame and then read every 
  fourth frame or whatever the frameskip is.
  deque max length formula = frameskip * (framestack - 1) + 1

Test GameController
https://hardwaretester.com/gamepad

Best lap-time without going off track
7:43:612
138.4 seconds
147.8 seconds
177.3 seconds

Why do we use the log in gradient-based reinforcement algorithms? (https://cs.stackexchange.com/questions/70518/why-do-we-use-the-log-in-gradient-based-reinforcement-algorithms)

PPO-LSTM - https://npitsillos.github.io/blog/2021/recurrent-ppo/